{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_conv2d(conv2d,X):\n",
    "    X = X.view((1,1)+X.shape)\n",
    "    Y = conv2d(X)\n",
    "    return Y.view(Y.shape[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2d = nn.Conv2d(in_channels=1,out_channels=1,kernel_size=(2,4),padding=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[[[ 0.0520,  0.3313, -0.0944, -0.3067],\n",
       "           [ 0.1631, -0.1631,  0.2143,  0.1469]]]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.3528], requires_grad=True)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(conv2d.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand(8,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3071, 0.2293, 0.1980, 0.3017, 0.4989, 0.0729, 0.4440, 0.6901],\n",
       "        [0.9908, 0.8686, 0.5838, 0.9625, 0.9649, 0.7039, 0.5867, 0.3070],\n",
       "        [0.7660, 0.5712, 0.4817, 0.9628, 0.4949, 0.0753, 0.1824, 0.0951],\n",
       "        [0.8314, 0.7899, 0.5693, 0.8867, 0.8812, 0.6821, 0.8693, 0.5379],\n",
       "        [0.9505, 0.3636, 0.0656, 0.2105, 0.7625, 0.2466, 0.6236, 0.1453],\n",
       "        [0.3830, 0.0662, 0.3829, 0.6124, 0.2808, 0.9951, 0.5030, 0.1448],\n",
       "        [0.4342, 0.1703, 0.8018, 0.1944, 0.8352, 0.5662, 0.3415, 0.2516],\n",
       "        [0.8983, 0.4369, 0.5357, 0.5475, 0.3326, 0.0220, 0.0309, 0.4350]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 7])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = comp_conv2d(conv2d,X)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.4483, 0.5435, 0.7802, 0.4577, 0.9300, 0.3441, 0.7269, 0.4602],\n",
       "          [0.1884, 0.6468, 0.5950, 0.4285, 0.7792, 0.7731, 0.5929, 0.6313],\n",
       "          [0.5635, 0.7854, 0.6549, 0.3817, 0.6771, 0.4003, 0.8342, 0.3016],\n",
       "          [0.7585, 0.3420, 0.7159, 0.7452, 0.9926, 0.3002, 0.1141, 0.9406],\n",
       "          [0.6275, 0.9018, 0.2602, 0.6920, 0.5311, 0.1054, 0.6560, 0.9605],\n",
       "          [0.2374, 0.0752, 0.6937, 0.5189, 0.3306, 0.3383, 0.3130, 0.4924],\n",
       "          [0.2083, 0.7087, 0.7715, 0.0776, 0.3144, 0.5793, 0.4307, 0.1706],\n",
       "          [0.2404, 0.8941, 0.4376, 0.6845, 0.1529, 0.7587, 0.1516, 0.0748]]]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.view((1,1)+X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 8, 8])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.view((1,1)+X.shape).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = comp_conv2d(conv2d,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5108, 0.5717, 0.5489, 0.6552, 0.4563, 0.6717, 0.3890],\n",
       "        [0.4059, 0.4578, 0.5258, 0.6593, 0.6248, 0.5261, 0.7327],\n",
       "        [0.3442, 0.5495, 0.5066, 0.4634, 0.5385, 0.6680, 0.5236],\n",
       "        [0.3192, 0.7941, 0.6113, 0.5786, 0.3440, 0.6248, 0.8533],\n",
       "        [0.4813, 0.3220, 0.5638, 0.5099, 0.8022, 0.5557, 0.4334],\n",
       "        [0.4750, 0.6986, 0.3165, 0.6621, 0.5027, 0.1969, 0.5945],\n",
       "        [0.4428, 0.2605, 0.4887, 0.6914, 0.5101, 0.3756, 0.4883],\n",
       "        [0.3349, 0.5894, 0.7850, 0.3152, 0.5457, 0.4127, 0.6245],\n",
       "        [0.2138, 0.4102, 0.4326, 0.3551, 0.3208, 0.5748, 0.4354]],\n",
       "       grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2d = nn.Conv2d(1,1,kernel_size=3,padding=1,stride=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2d = nn.Conv2d(1,1,kernel_size=(3,5),padding=(0,1),stride=(3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
